{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance de chiffres manuscrits (MNIST) : réseaux convolutionnels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Définition du 'backend' (Tensorflow ou Theano)\n",
    "from keras import backend as K\n",
    "\n",
    "# Pour Theano\n",
    "#K.set_image_dim_ordering('th')\n",
    "\n",
    "# Pour Tensorflow\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importation des données MNIST\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Redimensionnement des images [echantillon][canaux][largeur][hauteur]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# Pour Theano :\n",
    "# X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "\n",
    "# Normalisation entre 0 et 1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Encodage des sorties en catégories\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 592,074\n",
      "Trainable params: 592,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (5, 5), input_shape=(28, 28, 1..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Réseau convolutionnel simple\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 5, 5, input_shape=(28, 28, 1), activation='relu'))\n",
    "# Pour Theano :\n",
    "# model.add(Convolution2D(32, 5, 5, input_shape=(1, 28, 28), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Impression du modèle\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qkame\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "27s - loss: 0.2376 - acc: 0.9328 - val_loss: 0.0777 - val_acc: 0.9767\n",
      "Epoch 2/10\n",
      "26s - loss: 0.0719 - acc: 0.9785 - val_loss: 0.0518 - val_acc: 0.9817\n",
      "Epoch 3/10\n",
      "26s - loss: 0.0514 - acc: 0.9846 - val_loss: 0.0433 - val_acc: 0.9856\n",
      "Epoch 4/10\n",
      "26s - loss: 0.0411 - acc: 0.9874 - val_loss: 0.0382 - val_acc: 0.9873\n",
      "Epoch 5/10\n",
      "26s - loss: 0.0323 - acc: 0.9899 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "27s - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0341 - val_acc: 0.9886\n",
      "Epoch 7/10\n",
      "27s - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0336 - val_acc: 0.9885\n",
      "Epoch 8/10\n",
      "27s - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0331 - val_acc: 0.9898\n",
      "Epoch 9/10\n",
      "27s - loss: 0.0172 - acc: 0.9941 - val_loss: 0.0304 - val_acc: 0.9897\n",
      "Epoch 10/10\n",
      "26s - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0297 - val_acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x237348483c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apprentissage\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 98.90%\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Score : %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (5, 5), input_shape=(28, 28, 1..., activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Modèle CNN plus profond\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(30, 5, 5, input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Score : %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice  \n",
    "Appliquer les approches MLP et CNN sur le dataset *Fashion_MNIST* :  \n",
    "https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "#import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Importation des données MNIST\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Les données sont séparées en un set d'apprentissage et un set de test\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionnement des images [echantillon][canaux][largeur][hauteur]\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# Normalisation entre 0 et 1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Encodage des sorties en catégories\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 200)               320200    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 387,778\n",
      "Trainable params: 387,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Réseau convolutionnel simple\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, (3, 3)))  \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))   \n",
    " \n",
    "model.add(Convolution2D(64, (3, 3))) \n",
    "model.add(Activation('relu'))     \n",
    "model.add(Convolution2D(64, (3, 3)))     \n",
    "model.add(Activation('relu'))     \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))     \n",
    "model.add(Dropout(0.25))\n",
    "                \n",
    "model.add(Flatten())\n",
    "model.add(Dense(200)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5))      \n",
    "model.add(Dense(num_classes)) \n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Impression du modèle\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qkame\\AppData\\Roaming\\Python\\Python36\\site-packages\\keras\\models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "122s - loss: 1.7496 - acc: 0.3503 - val_loss: 1.4146 - val_acc: 0.4895\n",
      "Epoch 2/10\n",
      "122s - loss: 1.3799 - acc: 0.5038 - val_loss: 1.1767 - val_acc: 0.5828\n",
      "Epoch 3/10\n",
      "123s - loss: 1.2299 - acc: 0.5627 - val_loss: 1.0959 - val_acc: 0.6014\n",
      "Epoch 4/10\n",
      "122s - loss: 1.1262 - acc: 0.6018 - val_loss: 0.9826 - val_acc: 0.6529\n",
      "Epoch 5/10\n",
      "127s - loss: 1.0509 - acc: 0.6332 - val_loss: 0.9339 - val_acc: 0.6728\n",
      "Epoch 6/10\n",
      "195s - loss: 0.9817 - acc: 0.6533 - val_loss: 0.8816 - val_acc: 0.6830\n",
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "# Apprentissage\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
